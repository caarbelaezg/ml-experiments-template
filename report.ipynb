{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "involved-declaration",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "In this notebook we report progress on the project of house price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aerial-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confidential-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legal-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "successful-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(*, model, metric, X_train, y_train, X_test, y_test):\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    train_error = metric(y_train, train_predictions)\n",
    "    test_error = metric(y_test, test_predictions)\n",
    "    return {\n",
    "        \"train_predictions\": train_predictions,\n",
    "        \"test_predictions\": test_predictions,\n",
    "        \"train_error\": train_error,\n",
    "        \"test_error\": test_error\n",
    "    }\n",
    "\n",
    "def print_report(*, model, evaluation):\n",
    "    print(f\"Model used:\\n\\t{reg}\")\n",
    "    print(f\"Error:\\n\\ttrain set {evaluation['train_error']}\\n\\ttest error: {evaluation['test_error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hazardous-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "union-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "central-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.get_dataset(\n",
    "    partial(pd.read_csv, filepath_or_buffer=dataset_path),\n",
    "    splits=(\"train\", \"test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-pastor",
   "metadata": {},
   "source": [
    "**If you need to visualize anything from your training data, do it here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-speed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-policy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "specific-solid",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Before doing any complex Machine Learning model, let's try to solve the problem by having an initial educated guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aboriginal-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('average-price-per-neighborhood-regressor',\n",
      "                 AveragePricePerNeighborhoodRegressor())])\n",
      "Error:\n",
      "\ttrain set 33609.9990756996\n",
      "\ttest error: 34799.09487677742\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-04 15-12\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-singer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "indian-senate",
   "metadata": {},
   "source": [
    "## Linear Regression Model \n",
    "\n",
    "We want to try easy things first, so know lets see how a linear regression model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "willing-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge'],\n",
      "                                    force_dense_array=True, one_hot=True)),\n",
      "                ('standard-scaler', StandardScaler()),\n",
      "                ('linear-regressor', LinearRegression())])\n",
      "Error:\n",
      "\ttrain set 10951.953179992095\n",
      "\ttest error: 2967241310539.6943\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 15-50\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-colors",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "What can you learn about the errors your model is making? Try this:\n",
    "\n",
    "* Discretize the errors your model is making by some categorical variables.\n",
    "* Sort and discretize the errors your model is making and see what the features have in common in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-phone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-description",
   "metadata": {},
   "source": [
    "## Linear regression with Feature Engineering\n",
    "\n",
    "Probably the previous model is not good enough, let's see how is the performance of a model using some produced features.\n",
    "\n",
    "Techniques:\n",
    "1. Feature Cross\n",
    "2. Discretizer\n",
    "3. Add average per neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deluxe-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('averager', AveragePricePerNeighborhoodExtractor()),\n",
      "                ('discretizer',\n",
      "                 Discretizer(bins_per_column={'LotArea': 3, 'LotFrontage': 5},\n",
      "                             strategy='quantile')),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_categories={'LotArea': [0.0, 1.0,\n",
      "                                                                       2.0],\n",
      "                                                           'LotFrontage': [0.0,\n",
      "                                                                           1.0,\n",
      "                                                                           2.0,\n",
      "                                                                           3.0,\n",
      "                                                                           4.0]},\n",
      "                                    additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge',\n",
      "                                                                     'AveragePriceInNeihborhood'],\n",
      "                                    force_dense_array=True, one_hot=True)),\n",
      "                ('standard-scaler', StandardScaler()),\n",
      "                ('linear-regressor', LinearRegression())])\n",
      "Error:\n",
      "\ttrain set 11383.190533872741\n",
      "\ttest error: 6505946333741.948\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 15-48\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-consumption",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "What can you learn about the errors your model is making? Try this:\n",
    "\n",
    "* Discretize the errors your model is making by some categorical variables.\n",
    "* Sort or discretize the errors your model is making and see what the features have in common in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-merchandise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opened-borough",
   "metadata": {},
   "source": [
    "## Regularized Linear Regression\n",
    "\n",
    "Let's assume you are overfitting. Load the results of a linear regression model with regularized loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lesbian-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('discretizer',\n",
      "                 Discretizer(bins_per_column={'LotArea': 3, 'LotFrontage': 5},\n",
      "                             strategy='quantile')),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_categories={'LotArea': [0.0, 1.0,\n",
      "                                                                       2.0],\n",
      "                                                           'LotFrontage': [0.0,\n",
      "                                                                           1.0,\n",
      "                                                                           2.0,\n",
      "                                                                           3.0,\n",
      "                                                                           4.0]},\n",
      "                                    additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge'],\n",
      "                                    force_dense_array=True, one_hot=True)),\n",
      "                ('standard-scaler', StandardScaler()),\n",
      "                ('ridge-regressor', Ridge(alpha=100))])\n",
      "Error:\n",
      "\ttrain set 11558.746052020384\n",
      "\ttest error: 17943.39421460489\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 15-43\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-authority",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "What can you learn about the errors your model is making? Try this:\n",
    "\n",
    "* Discretize the errors your model is making by some categorical variables.\n",
    "* Sort or discretize the errors your model is making and see what the features have in common in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-science",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hidden-begin",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision trees ofer great complexity, they can fit even a noisy dataset almost perfectly. Let's see how it behaves on the task at hand. \n",
    "\n",
    "**Overfiting case**\n",
    "Let's see the results for a model that has greatly overfit the data, this wouldn't be an ideal model, but at least it could tell that our model is powerful enough for the task at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "theoretical-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge'],\n",
      "                                    force_dense_array=True)),\n",
      "                ('decision-tree-regressor', DecisionTreeRegressor())])\n",
      "Error:\n",
      "\ttrain set 0.0\n",
      "\ttest error: 27141.272597526167\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 15-51\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-physiology",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "What can you learn about the errors your model is making? Try this:\n",
    "\n",
    "* Discretize the errors your model is making by some categorical variables.\n",
    "* Sort or discretize the errors your model is making and see what the features have in common in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-anime",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blessed-pattern",
   "metadata": {},
   "source": [
    "**Using best hyper params** Now let's see thow much a simple decision tree can give us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fabulous-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge'],\n",
      "                                    force_dense_array=True)),\n",
      "                ('decision-tree-regressor',\n",
      "                 DecisionTreeRegressor(max_depth=8, max_features='auto'))])\n",
      "Error:\n",
      "\ttrain set 8884.676197932415\n",
      "\ttest error: 28098.13544441429\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 15-54\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-order",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "assigned-acting",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Now it is time to use a model that can properly help us to regularize the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dress-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used:\n",
      "\tPipeline(steps=[('age-extractor', AgeExtractor()),\n",
      "                ('categorical-encoder',\n",
      "                 CategoricalEncoder(additional_pass_through_columns=['HouseAge',\n",
      "                                                                     'RemodAddAge',\n",
      "                                                                     'GarageAge'],\n",
      "                                    force_dense_array=True)),\n",
      "                ('random-forest-regressor',\n",
      "                 RandomForestRegressor(max_depth=18, max_features=20,\n",
      "                                       n_estimators=512))])\n",
      "Error:\n",
      "\ttrain set 5741.839429708461\n",
      "\ttest error: 17727.675141267133\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"models\", \"2021-06-05 16-08\", \"model.joblib\")\n",
    "reg = joblib.load(model_path)\n",
    "evaluation = evaluate_model(\n",
    "    model=reg,\n",
    "    metric=metrics.custom_error,\n",
    "    X_train=dataset[\"train\"][0],\n",
    "    y_train=dataset[\"train\"][1],\n",
    "    X_test=dataset[\"test\"][0],\n",
    "    y_test=dataset[\"test\"][1]\n",
    ")\n",
    "print_report(model=reg, evaluation=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-greeting",
   "metadata": {},
   "source": [
    "**Error Analysis**\n",
    "\n",
    "What can you learn about the errors your model is making? Try this:\n",
    "\n",
    "* Discretize the errors your model is making by some categorical variables.\n",
    "* Sort or discretize the errors your model is making and see what the features have in common in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-glance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
